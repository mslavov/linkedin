---
title: "CLI Wars: Benchmarking Claude Code vs Google vs OpenAI"
created_date: 2025-09-09
tags: ["ai-tools", "claude-code", "benchmarking", "developer-tools", "comparison"]
priority: normal
status: new
original_issue: 33
---

## Core Idea
Create and run benchmarks comparing Claude Code against Google and OpenAI's CLIs to understand ROI and performance differences.

## Key Points
- Claude Code is currently best but competitors are catching up
- ROI comparison might show different winners
- Use existing Claude Code eval repo for testing all CLIs
- Create transparent, reproducible benchmarks
- Share results with the community

## Potential Hook
"Claude Code is winning the CLI race. But for how long? I built benchmarks to find out."

## Connection to Previous Content
- Extends the Claude Code evals work
- Continues theme of testing and measuring AI tools
- Provides practical insights for tool selection

## Notes
- Reference repo: https://github.com/mslavov/claude-code-eval
- Could create a standardized test suite
- Consider different metrics: speed, accuracy, cost, developer experience
- Opportunity to help others make informed tool choices